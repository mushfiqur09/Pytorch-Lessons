{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab714e7-e195-42b5-ad39-9d2a70cebdf5",
   "metadata": {},
   "source": [
    "# Pytorch basics\n",
    "Main target is to go through the tutorials from [here](https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fffa6bde-edc4-4c99-84ef-85e8adaffb70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419becc7-c989-48f3-a3d8-de4953b45cf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tutorial 2: Tensor objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36573478-3049-42de-84a9-f82ae2335671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ways to define torch objects\n",
    "x = torch.empty(2, 2, dtype = torch.int)\n",
    "y = torch.rand(2, 2, dtype = torch.float)\n",
    "z = torch.zeros(2, 2)\n",
    "z  = torch.ones(2, 2)\n",
    "a = torch.tensor([[2,2], [3,3]], dtype = torch.float)\n",
    "\n",
    "# I can do all these operations now\n",
    "z = x + a\n",
    "z = torch.add(x, a)\n",
    "z = torch.sub(x, a)\n",
    "z = torch.mul(x, a)\n",
    "z = torch.div(x, a)\n",
    "\n",
    "# slicing, reshaping data\n",
    "x[0, :]\n",
    "x.view(4) \n",
    "x.view(-1, 1)\n",
    "x.reshape(1, 4)\n",
    "\n",
    "# juggling between numpy and torch\n",
    "z = z.numpy(); # print(type(z))\n",
    "z = torch.from_numpy(z)\n",
    "\n",
    "# A special case where we need a variable who's gradients need to be calculated\n",
    "w = torch.ones(5, requires_grad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f1708-3db1-474b-bb59-96aa5a1db156",
   "metadata": {},
   "source": [
    "Recap:\n",
    "* numpy, torch -> libraries/ packages (inside that there'll be classes, functions, datatypes defined)\n",
    "* x = torch.zeros(2) creates a torch object named x; I can see that using type(x)\n",
    "* x.dtype will show the data type of the torch object x\n",
    "* you'll notice sometimes we do x.type and sometimes x.size(). This is because type is an attribute of x and size is a function defined under that object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa039b9b-0573-42a9-977e-2e31c9a3964f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sometimes if CUDA is available, it can accelerate a lot of computation. Looks like for my case, it is not but keeping the codes anyways\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda available')\n",
    "    device = torch.device(\"cuda\")\n",
    "    x = torch.ones(5, device = device)\n",
    "    y = torch.ones(5);\n",
    "    y = y.to(device);\n",
    "    z = x + y # is faster because they are both in GPU\n",
    "    # careful: z.numpy() cannot be done now cause numpy cannot work in GPU\n",
    "    z = z.to(\"cpu\")\n",
    "    # Check number of CUDA devices available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031a4644-adef-4ef1-a7a3-81c1dc85cccf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tutorial 3: Gradient Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ab5b3bf-2bf8-4b0e-a042-e61eecf59a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3, requires_grad = True) # print(x) shows the flag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ba47ae5-c7dd-4667-9b18-b4f6215a683f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.9973, 1.6517, 1.1172], grad_fn=<AddBackward0>)\n",
      "tensor(8.6401, grad_fn=<MeanBackward0>)\n",
      "tensor([24.3784, 25.3258,  8.2014])\n"
     ]
    }
   ],
   "source": [
    "y = x + 2; # Think of y as the output neuron and x and 2 are the input neurons. \n",
    "# If the RHS has requires_grad = True set, pytorch will automatically create an attribute grad_fn which is a function that can calculate dy/dx\n",
    "print(y)\n",
    "z = y * y * 2; \n",
    "z = z.mean(); \n",
    "print(z)\n",
    "z.backward() # dz / dx # mean opeartion is necessary here because if z is a vector then it's a mess.\n",
    "\n",
    "z = y * y * 2; # if z is not a scalar\n",
    "v = torch.tensor([0.1, 1.0, .001], dtype = torch.float32); # 3d cause x is also 3d\n",
    "z.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1cdfb-d577-46ab-ad07-087eefcbdb73",
   "metadata": {},
   "source": [
    "$Notice$ : z.backward() does not work for \n",
    "* vector z. I didn't understand how the vector v in the previous code was defined\n",
    "* if I don't specify requires_grad = true\n",
    "\n",
    "So, the part that fascillitates calculation of gradient to every new variable that are dependent on the original is the \"requires_grad = True\" command. \n",
    "This can be potentially dangerous as if we define a new varaible that depends on it, the new variable will start becoming a part of the gradients. \n",
    "To detach the variable from gradients there are three options: \n",
    "\n",
    "```python \n",
    "x.requires_grad_(False)\n",
    "x.detach()\n",
    "with torch.no_grad():\n",
    "    {\n",
    "        y = ...\n",
    "    }\n",
    "```\n",
    "\n",
    "$Important$: *.grad keeps accumulating. So, we must empty the grad varaibles if we don't want it. The way to do that is by adding ```weights.grad.zero_()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f5fb5e96-7365-4a50-9ba6-a64d87ea6bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad = True);\n",
    "for epoch in range(3):\n",
    "    model_output = (weights * 3).sum();\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    #weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c2484c-0a4d-42b1-9593-84cc11c5af74",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tutorial 4: Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6091a80-0b7c-40ed-a122-10ad46859596",
   "metadata": {},
   "source": [
    "$\\textbf{Chain rule:}$ x -> y = a(x) -> z = b(y); and we want to know \n",
    "\n",
    "dz/dx = dz/dy. dy/dx.\n",
    "\n",
    "We use this to perform backpropagation in three steps: \n",
    "1. Forward pass\n",
    "2. Compute the loss\n",
    "3. backward pass & update\n",
    "\n",
    "See the image at [this](https://www.youtube.com/watch?v=3Kb0QS6z7WA&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=4) link (5:35) for a better understanding of the variables w, x, y, yhat, s, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e066a7e1-4c14-4b9a-b7a3-bc8dc1ec31f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad = True)\n",
    "\n",
    "yHat = w * x # forward pass\n",
    "\n",
    "L = (yHat - y)**2\n",
    "\n",
    "L.backward(); # backward pass\n",
    "\n",
    "print(w.grad) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eb1aca-6f7b-420a-a2b8-60f65c1aea64",
   "metadata": {},
   "source": [
    "So, backpropagation is as simple as just typing L.backward()\n",
    "and calculating gradient is also just parameter.grad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f99f827-00ca-4f54-adb9-08e37abfd6cd",
   "metadata": {},
   "source": [
    "### Tutorial 5: GD with autograd and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b360a-d1fd-4bdf-837f-a0e7adf21f69",
   "metadata": {},
   "source": [
    "Try 1: Let's do it manually first to really appreciate what pytorch is doing for us. \n",
    "\n",
    "X = numpy.array([1, 2, 3, 4], dtype = \"float32\") doesn't work due to some formatting issue. See [this](https://stackoverflow.com/questions/43911844/numpy-float32-gives-different-value-from-dtype-float32-in-array) for details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2fd17948-76a5-4290-af10-e097e70c13b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training : f(5) = 0\n",
      "epoch 1: w = 1.200, loss = 30.000\n",
      "epoch 21: w = 2.000, loss = 0.000\n",
      "epoch 41: w = 2.000, loss = 0.000\n",
      "epoch 61: w = 2.000, loss = 0.000\n",
      "epoch 81: w = 2.000, loss = 0.000\n",
      "Prediction after training: f(5) = 9.99999977350235\n"
     ]
    }
   ],
   "source": [
    "# linear regression example (f = w* x). That is, we'll try to fit a set of data to this formula.\n",
    "X = numpy.array([1, 2, 3, 4], dtype = numpy.float32);\n",
    "Y = numpy.array([2, 4, 6, 8], dtype = numpy.float32); \"\"\" these are our input data. we'll create a model that fits this data. That is find the optimum w\"\"\"\n",
    "\n",
    "w = 0 # wguess\n",
    "# model\n",
    "def forward(x):\n",
    "    return w * x;\n",
    "\n",
    "# loss\n",
    "def loss(y, yHat):\n",
    "    return ((yHat - y)**2).mean();\n",
    "\n",
    "# gradient\n",
    "def gradient(x, y, yHat):\n",
    "    return numpy.dot(2 * x, yHat - y).mean(); \n",
    "print(f'Prediction before training : f(5) = {forward(5)}');\n",
    "\n",
    "# Training\n",
    "learningRate = 0.01\n",
    "nIters = 100;\n",
    "\n",
    "for epoch in range(nIters):\n",
    "    YHat = forward(X);\n",
    "    L = loss(Y, YHat);\n",
    "    dw = gradient(X, Y, YHat);\n",
    "    \n",
    "    # update weights\n",
    "    w -= learningRate * dw\n",
    "    \n",
    "    if epoch % 20 ==0:\n",
    "        print(f'epoch {epoch + 1}: w = {w:.3f}, loss = {L:0.3f}');\n",
    "print(f'Prediction after training: f(5) = {forward(5)}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b253a1-32ae-4266-ba6f-264ea3f9b229",
   "metadata": {
    "tags": []
   },
   "source": [
    "Try 2: pytorch (calculate gradient automatically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3e520ece-1a11-4a59-83a6-6f9b6f0d4eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training : f(5) = 0.0\n",
      "epoch 1: w = 0.300, loss = 30.000\n",
      "epoch 21: w = 1.934, loss = 0.045\n",
      "epoch 41: w = 1.997, loss = 0.000\n",
      "epoch 61: w = 2.000, loss = 0.000\n",
      "epoch 81: w = 2.000, loss = 0.000\n",
      "Prediction after training: f(5) = 9.999998092651367\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32);\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32); \"\"\" these are our input data. we'll create a model that fits this data. That is find the optimum w\"\"\"\n",
    "\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True) # wguess\n",
    "\n",
    "# model (same as before)\n",
    "def forward(x):\n",
    "    return w * x;\n",
    " \n",
    "# loss (same as before)\n",
    "def loss(y, yHat):\n",
    "    return ((yHat - y)**2).mean();\n",
    "\n",
    "# gradient -> no need to write an explicit function!\n",
    "\n",
    "# Training\n",
    "learningRate = 0.01\n",
    "nIters = 100;\n",
    "\n",
    "print(f'Prediction before training : f(5) = {forward(5)}');\n",
    "for epoch in range(nIters):\n",
    "    YHat = forward(X);\n",
    "    \n",
    "    L = loss(Y, YHat);\n",
    "    \n",
    "    L.backward(); \n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad(): # important: This is mandatory as we don't want to tie w with \n",
    "        w -= learningRate * w.grad;\n",
    "\n",
    "    w.grad.zero_(); # have to make the gradients zero again. Why though? cause the L.backward() line will keep accumulating w.grad if we don't set it to zero every time\n",
    "    \n",
    "    if epoch % 20 ==0:\n",
    "        print(f'epoch {epoch + 1}: w = {w:.3f}, loss = {L:0.3f}');\n",
    "print(f'Prediction after training: f(5) = {forward(5)}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f10c7-3e74-4252-b1aa-fa6a8e095452",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tutorial 6: Training pipeline: model, loss, and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c286571-43a6-43ef-a997-95db0efd1f56",
   "metadata": {},
   "source": [
    "It turns out, Pytorch lets us replace the manually computed loss, parameter updates. Steps: \n",
    "\n",
    "1. Design model (input, output, forward pass)\n",
    "2. loss and optimizer\n",
    "3. Tranining loop:\n",
    "* forward pass: compute prediction\n",
    "* backward pass: gradients\n",
    "* update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c2601be4-8321-4655-aa40-d43928e8aec7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training : f(5) = -1.354038953781128\n",
      "epoch 1: w = -0.104, loss = 35.267\n",
      "epoch 21: w = 1.495, loss = 0.335\n",
      "epoch 41: w = 1.563, loss = 0.276\n",
      "epoch 61: w = 1.589, loss = 0.245\n",
      "epoch 81: w = 1.613, loss = 0.217\n",
      "Prediction after training: f(5) = tensor([[8.1729]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn \n",
    "\n",
    "learningRate = 0.01\n",
    "nIters = 100;\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype = torch.float32); # need the general case of nsamples and nfeatures so have to cast it into this form\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype = torch.float32); \"\"\" these are our input data. we'll create a model that fits this data. That is find the optimum w\"\"\"\n",
    "\n",
    "X_test = torch.tensor([5], dtype = torch.float32);\n",
    "\n",
    "nSamples, nFeatures = X.shape;\n",
    "inputSize = nFeatures; outputSize = nFeatures;\n",
    "\n",
    "model = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "# loss and gradient can be automatically calculated (newly added)\n",
    "LossFun = torch.nn.MSELoss();\n",
    "optimizerFun = torch.optim.SGD(model.parameters(), lr=learningRate); \n",
    "\n",
    "print(f'Prediction before training : f(5) = {model(X_test).item()}');\n",
    "\n",
    "for epoch in range(nIters):\n",
    "    YHat = model(X);\n",
    "    \n",
    "    L = loss(Y, YHat);    \n",
    "    \n",
    "    L.backward(); \n",
    "    \n",
    "    optimizerFun.step();\n",
    "    \n",
    "    optimizerFun.zero_grad(); # emptying the gradients\n",
    "    \n",
    "    if epoch % 20 ==0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f'epoch {epoch + 1}: w = {w[0][0].item():.3f}, loss = {L:0.3f}');\n",
    "        \n",
    "print(f'Prediction after training: f(5) = {forward(5)}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e71f7c37-c031-4dd5-87fe-76c95169af50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can define the model more formally too like this\n",
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputDim, outputDim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = torch.nn.Linear(inputDim, outputDim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "model = LinearRegression(inputSize, outputSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f5546-2e8c-422c-9b16-d74c0861e30a",
   "metadata": {},
   "source": [
    "### Tutorial 7: Recap of Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b5496bd-cc0c-4170-94c7-8b374fa239a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f4315c-caec-4af4-a1b3-2787ee7f6d60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15e79a2ca50>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ecae3-6421-4252-a836-39eda99b9f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
