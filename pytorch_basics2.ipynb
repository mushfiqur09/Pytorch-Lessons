{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab714e7-e195-42b5-ad39-9d2a70cebdf5",
   "metadata": {},
   "source": [
    "# Pytorch basics\n",
    "Main target is to go through the tutorials from [here](https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fffa6bde-edc4-4c99-84ef-85e8adaffb70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419becc7-c989-48f3-a3d8-de4953b45cf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tutorial 2: Tensor objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36573478-3049-42de-84a9-f82ae2335671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ways to define torch objects\n",
    "x = torch.empty(2, 2, dtype = torch.int)\n",
    "y = torch.rand(2, 2, dtype = torch.float)\n",
    "z = torch.zeros(2, 2)\n",
    "z  = torch.ones(2, 2)\n",
    "a = torch.tensor([[2,2], [3,3]], dtype = torch.float)\n",
    "\n",
    "# I can do all these operations now\n",
    "z = x + a\n",
    "z = torch.add(x, a)\n",
    "z = torch.sub(x, a)\n",
    "z = torch.mul(x, a)\n",
    "z = torch.div(x, a)\n",
    "\n",
    "# slicing, reshaping data\n",
    "x[0, :]\n",
    "x.view(4) \n",
    "x.view(-1, 1)\n",
    "x.reshape(1, 4)\n",
    "\n",
    "# juggling between numpy and torch\n",
    "z = z.numpy(); # print(type(z))\n",
    "z = torch.from_numpy(z)\n",
    "\n",
    "# A special case where we need a variable who's gradients need to be calculated\n",
    "w = torch.ones(5, requires_grad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f1708-3db1-474b-bb59-96aa5a1db156",
   "metadata": {},
   "source": [
    "Recap:\n",
    "* numpy, torch -> libraries/ packages (inside that there'll be classes, functions, datatypes defined)\n",
    "* x = torch.zeros(2) creates a torch object named x; I can see that using type(x)\n",
    "* x.dtype will show the data type of the torch object x\n",
    "* you'll notice sometimes we do x.type and sometimes x.size(). This is because type is an attribute of x and size is a function defined under that object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa039b9b-0573-42a9-977e-2e31c9a3964f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sometimes if CUDA is available, it can accelerate a lot of computation. Looks like for my case, it is not but keeping the codes anyways\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda available')\n",
    "    device = torch.device(\"cuda\")\n",
    "    x = torch.ones(5, device = device)\n",
    "    y = torch.ones(5);\n",
    "    y = y.to(device);\n",
    "    z = x + y # is faster because they are both in GPU\n",
    "    # careful: z.numpy() cannot be done now cause numpy cannot work in GPU\n",
    "    z = z.to(\"cpu\")\n",
    "    # Check number of CUDA devices available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031a4644-adef-4ef1-a7a3-81c1dc85cccf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tutorial 3: Gradient Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ab5b3bf-2bf8-4b0e-a042-e61eecf59a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3, requires_grad = True) # print(x) shows the flag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ba47ae5-c7dd-4667-9b18-b4f6215a683f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.9973, 1.6517, 1.1172], grad_fn=<AddBackward0>)\n",
      "tensor(8.6401, grad_fn=<MeanBackward0>)\n",
      "tensor([24.3784, 25.3258,  8.2014])\n"
     ]
    }
   ],
   "source": [
    "y = x + 2; # Think of y as the output neuron and x and 2 are the input neurons. \n",
    "# If the RHS has requires_grad = True set, pytorch will automatically create an attribute grad_fn which is a function that can calculate dy/dx\n",
    "print(y)\n",
    "z = y * y * 2; \n",
    "z = z.mean(); \n",
    "print(z)\n",
    "z.backward() # dz / dx # mean opeartion is necessary here because if z is a vector then it's a mess.\n",
    "\n",
    "z = y * y * 2; # if z is not a scalar\n",
    "v = torch.tensor([0.1, 1.0, .001], dtype = torch.float32); # 3d cause x is also 3d\n",
    "z.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1cdfb-d577-46ab-ad07-087eefcbdb73",
   "metadata": {},
   "source": [
    "$Notice$ : z.backward() does not work for \n",
    "* vector z. I didn't understand how the vector v in the previous code was defined\n",
    "* if I don't specify requires_grad = true\n",
    "\n",
    "So, the part that fascillitates calculation of gradient to every new variable that are dependent on the original is the \"requires_grad = True\" command. \n",
    "This can be potentially dangerous as if we define a new varaible that depends on it, the new variable will start becoming a part of the gradients. \n",
    "To detach the variable from gradients there are three options: \n",
    "\n",
    "```python \n",
    "x.requires_grad_(False)\n",
    "x.detach()\n",
    "with torch.no_grad():\n",
    "    {\n",
    "        y = ...\n",
    "    }\n",
    "```\n",
    "\n",
    "$Important$: *.grad keeps accumulating. So, we must empty the grad varaibles if we don't want it. The way to do that is by adding ```weights.grad.zero_()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f5fb5e96-7365-4a50-9ba6-a64d87ea6bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad = True);\n",
    "for epoch in range(3):\n",
    "    model_output = (weights * 3).sum();\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    #weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c2484c-0a4d-42b1-9593-84cc11c5af74",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tutorial 4: Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6091a80-0b7c-40ed-a122-10ad46859596",
   "metadata": {},
   "source": [
    "$\\textbf{Chain rule:}$ x -> y = a(x) -> z = b(y); and we want to know \n",
    "\n",
    "dz/dx = dz/dy. dy/dx.\n",
    "\n",
    "We use this to perform backpropagation in three steps: \n",
    "1. Forward pass\n",
    "2. Compute the loss\n",
    "3. backward pass & update\n",
    "\n",
    "See the image at [this](https://www.youtube.com/watch?v=3Kb0QS6z7WA&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=4) link (5:35) for a better understanding of the variables w, x, y, yhat, s, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e066a7e1-4c14-4b9a-b7a3-bc8dc1ec31f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad = True)\n",
    "\n",
    "yHat = w * x # forward pass\n",
    "\n",
    "L = (yHat - y)**2\n",
    "\n",
    "L.backward(); # backward pass\n",
    "\n",
    "print(w.grad) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eb1aca-6f7b-420a-a2b8-60f65c1aea64",
   "metadata": {},
   "source": [
    "So, backpropagation is as simple as just typing L.backward()\n",
    "and calculating gradient is also just parameter.grad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f99f827-00ca-4f54-adb9-08e37abfd6cd",
   "metadata": {},
   "source": [
    "### Tutorial 5: GD with autograd and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b360a-d1fd-4bdf-837f-a0e7adf21f69",
   "metadata": {},
   "source": [
    "Try 1: Let's do it manually first to really appreciate what pytorch is doing for us. \n",
    "\n",
    "X = numpy.array([1, 2, 3, 4], dtype = \"float32\") doesn't work due to some formatting issue. See [this](https://stackoverflow.com/questions/43911844/numpy-float32-gives-different-value-from-dtype-float32-in-array) for details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2fd17948-76a5-4290-af10-e097e70c13b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training : f(5) = 0\n",
      "epoch 1: w = 1.200, loss = 30.000\n",
      "epoch 21: w = 2.000, loss = 0.000\n",
      "epoch 41: w = 2.000, loss = 0.000\n",
      "epoch 61: w = 2.000, loss = 0.000\n",
      "epoch 81: w = 2.000, loss = 0.000\n",
      "Prediction after training: f(5) = 9.99999977350235\n"
     ]
    }
   ],
   "source": [
    "# linear regression example (f = w* x). That is, we'll try to fit a set of data to this formula.\n",
    "X = numpy.array([1, 2, 3, 4], dtype = numpy.float32);\n",
    "Y = numpy.array([2, 4, 6, 8], dtype = numpy.float32); \"\"\" these are our input data. we'll create a model that fits this data. That is find the optimum w\"\"\"\n",
    "\n",
    "w = 0 # wguess\n",
    "# model\n",
    "def forward(x):\n",
    "    return w * x;\n",
    "\n",
    "# loss\n",
    "def loss(y, yHat):\n",
    "    return ((yHat - y)**2).mean();\n",
    "\n",
    "# gradient\n",
    "def gradient(x, y, yHat):\n",
    "    return numpy.dot(2 * x, yHat - y).mean(); \n",
    "print(f'Prediction before training : f(5) = {forward(5)}');\n",
    "\n",
    "# Training\n",
    "learningRate = 0.01\n",
    "nIters = 100;\n",
    "\n",
    "for epoch in range(nIters):\n",
    "    YHat = forward(X);\n",
    "    L = loss(Y, YHat);\n",
    "    dw = gradient(X, Y, YHat);\n",
    "    \n",
    "    # update weights\n",
    "    w -= learningRate * dw\n",
    "    \n",
    "    if epoch % 20 ==0:\n",
    "        print(f'epoch {epoch + 1}: w = {w:.3f}, loss = {L:0.3f}');\n",
    "print(f'Prediction after training: f(5) = {forward(5)}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b253a1-32ae-4266-ba6f-264ea3f9b229",
   "metadata": {
    "tags": []
   },
   "source": [
    "Try 2: pytorch (calculate gradient automatically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3e520ece-1a11-4a59-83a6-6f9b6f0d4eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training : f(5) = 0.0\n",
      "epoch 1: w = 0.300, loss = 30.000\n",
      "epoch 21: w = 1.934, loss = 0.045\n",
      "epoch 41: w = 1.997, loss = 0.000\n",
      "epoch 61: w = 2.000, loss = 0.000\n",
      "epoch 81: w = 2.000, loss = 0.000\n",
      "Prediction after training: f(5) = 9.999998092651367\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32);\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32); \"\"\" these are our input data. we'll create a model that fits this data. That is find the optimum w\"\"\"\n",
    "\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True) # wguess\n",
    "\n",
    "# model (same as before)\n",
    "def forward(x):\n",
    "    return w * x;\n",
    " \n",
    "# loss (same as before)\n",
    "def loss(y, yHat):\n",
    "    return ((yHat - y)**2).mean();\n",
    "\n",
    "# gradient -> no need to write an explicit function!\n",
    "\n",
    "# Training\n",
    "learningRate = 0.01\n",
    "nIters = 100;\n",
    "\n",
    "print(f'Prediction before training : f(5) = {forward(5)}');\n",
    "for epoch in range(nIters):\n",
    "    YHat = forward(X);\n",
    "    \n",
    "    L = loss(Y, YHat);\n",
    "    \n",
    "    L.backward(); \n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad(): # important: This is mandatory as we don't want to tie w with \n",
    "        w -= learningRate * w.grad;\n",
    "\n",
    "    w.grad.zero_(); # have to make the gradients zero again. Why though? cause the L.backward() line will keep accumulating w.grad if we don't set it to zero every time\n",
    "    \n",
    "    if epoch % 20 ==0:\n",
    "        print(f'epoch {epoch + 1}: w = {w:.3f}, loss = {L:0.3f}');\n",
    "print(f'Prediction after training: f(5) = {forward(5)}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f10c7-3e74-4252-b1aa-fa6a8e095452",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tutorial 6: Training pipeline: model, loss, and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c286571-43a6-43ef-a997-95db0efd1f56",
   "metadata": {},
   "source": [
    "It turns out, Pytorch lets us replace the manually computed loss, parameter updates. Steps: \n",
    "\n",
    "1. Design model (input, output, forward pass)\n",
    "2. loss and optimizer\n",
    "3. Tranining loop:\n",
    "* forward pass: compute prediction\n",
    "* backward pass: gradients\n",
    "* update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c2601be4-8321-4655-aa40-d43928e8aec7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training : f(5) = -1.354038953781128\n",
      "epoch 1: w = -0.104, loss = 35.267\n",
      "epoch 21: w = 1.495, loss = 0.335\n",
      "epoch 41: w = 1.563, loss = 0.276\n",
      "epoch 61: w = 1.589, loss = 0.245\n",
      "epoch 81: w = 1.613, loss = 0.217\n",
      "Prediction after training: f(5) = tensor([[8.1729]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn \n",
    "\n",
    "learningRate = 0.01\n",
    "nIters = 100;\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype = torch.float32); # need the general case of nsamples and nfeatures so have to cast it into this form\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype = torch.float32); \"\"\" these are our input data. we'll create a model that fits this data. That is find the optimum w\"\"\"\n",
    "\n",
    "X_test = torch.tensor([5], dtype = torch.float32);\n",
    "\n",
    "nSamples, nFeatures = X.shape;\n",
    "inputSize = nFeatures; outputSize = nFeatures;\n",
    "\n",
    "model = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "# loss and gradient can be automatically calculated (newly added)\n",
    "LossFun = torch.nn.MSELoss();\n",
    "optimizerFun = torch.optim.SGD(model.parameters(), lr=learningRate); \n",
    "\n",
    "print(f'Prediction before training : f(5) = {model(X_test).item()}');\n",
    "\n",
    "for epoch in range(nIters):\n",
    "    YHat = model(X);\n",
    "    \n",
    "    L = loss(Y, YHat);    \n",
    "    \n",
    "    L.backward(); \n",
    "    \n",
    "    optimizerFun.step();\n",
    "    \n",
    "    optimizerFun.zero_grad(); # emptying the gradients\n",
    "    \n",
    "    if epoch % 20 ==0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f'epoch {epoch + 1}: w = {w[0][0].item():.3f}, loss = {L:0.3f}');\n",
    "        \n",
    "print(f'Prediction after training: f(5) = {forward(5)}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e71f7c37-c031-4dd5-87fe-76c95169af50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can define the model more formally too like this\n",
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputDim, outputDim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = torch.nn.Linear(inputDim, outputDim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "    \n",
    "model = LinearRegression(inputSize, outputSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f5546-2e8c-422c-9b16-d74c0861e30a",
   "metadata": {},
   "source": [
    "### Tutorial 7: Recap of Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5496bd-cc0c-4170-94c7-8b374fa239a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f4315c-caec-4af4-a1b3-2787ee7f6d60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2476aed1a10>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCu0lEQVR4nO3deXhU5eH28e9kmSSEZEJYElIIgiKgLCoIBqgLTaUU+EGJAgqKSmvfNqKAS6WK1laNO7iCWopaQRYVFK0LRkXRsIuCKIiiRCABhcxAIJNk5rx/HAgEAjLJJM9kcn+uay7POTOZ3FOUufucc57HYVmWhYiIiEgdiTAdQERERBoWlQ8RERGpUyofIiIiUqdUPkRERKROqXyIiIhInVL5EBERkTql8iEiIiJ1SuVDRERE6lSU6QBH8/v9bN++nYSEBBwOh+k4IiIichIsy2Lv3r2kpaUREXHisY2QKx/bt2+ndevWpmOIiIhINeTn59OqVasTvibkykdCQgJgh09MTDScRkRERE6Gx+OhdevWFd/jJxJy5ePQqZbExESVDxERkXrmZC6Z0AWnIiIiUqdUPkRERKROqXyIiIhInVL5EBERkTql8iEiIiJ1SuVDRERE6pTKh4iIiNQplQ8RERGpUyofIiIiUqdUPkRERKROqXyIiIhInVL5EBERkTql8iEiItJQ+Mphzij4+n9GYwRUPnw+H5MnT6Zt27bExcVx6qmn8q9//QvLsipeY1kWd9xxBy1btiQuLo7MzEy++eaboAcXERGRAL13J3z9Brx6LezfbSxGQOXj/vvvZ9q0aTzxxBN89dVX3H///TzwwAM8/vjjFa954IEHeOyxx5g+fTrLly8nPj6e/v37U1JSEvTwIiIicpLWvwJ5T9jbQ5+ERsnGokQF8uJPP/2UIUOGMHDgQABOOeUUXnrpJVasWAHYox5Tp07l9ttvZ8iQIQC88MILpKSksHDhQkaOHBnk+CIiIvKLCjfAa9fZ233GwxlDjMYJaOSjd+/e5ObmsmnTJgA+//xzli5dyoABAwDYsmULBQUFZGZmVvyMy+WiV69e5OXlBTG2iIiInJQDRTB3FJTth3YXQr/JphMFNvJx66234vF46NixI5GRkfh8Pu655x5GjRoFQEFBAQApKSmVfi4lJaXiuaN5vV68Xm/FvsfjCegDiIiIyHH4/bDgz7D7O3C1hqz/QGRAX/21IqCRj3nz5jFr1ixmz57NmjVreP7553nooYd4/vnnqx0gJycHl8tV8WjdunW130tERESO8NGDsOltiIyBEf+F+KamEwEBlo+bb76ZW2+9lZEjR9KlSxeuuOIKJkyYQE5ODgCpqakAFBYWVvq5wsLCiueONmnSJNxud8UjPz+/Op9DREREjrTpHfjQ/n5m8FRIO9tonCMFVD72799PRETlH4mMjMTv9wPQtm1bUlNTyc3NrXje4/GwfPlyMjIyqnzPmJgYEhMTKz1ERESkBn7+Fl79E2DBuX+Esy43naiSgE78DB48mHvuuYf09HTOPPNMPvvsMx555BGuueYaABwOB+PHj+fuu++mffv2tG3blsmTJ5OWlsbQoUNrI7+IiIgcqbQY5l4BJW5o1RP655hOdIyAysfjjz/O5MmT+etf/8rOnTtJS0vjz3/+M3fccUfFa2655RaKi4u59tprKSoqom/fvrz99tvExsYGPbyIiIgcwbLg9eth55cQ3wKGvwBRTtOpjuGwjpyeNAR4PB5cLhdut1unYERERAKR9xS8MwkiomDMImjTu85+dSDf31rbRUREJBx8vxTevd3e7n9vnRaPQKl8iIiI1HfubTD/KrB80HUE9LzWdKITUvkQERGpz8q9MO8KKN4FKV1g0FRwOEynOiGVDxERkfrsrVtg22qITbInEnM2Mp3oF6l8iIiI1Fern4fVzwEOyJoByW1NJzopKh8iIiL10Y+r4X832dv9boP2mSd+fQhR+RAREalv9u2yr/PwlULHQdD3RtOJAqLyISIiUp/4yuHlq8GzDZqeBkOnQUT9+jqvX2lFREQautx/wPcfg7MxjJgFsfVvQk6VDxERkfpi/avw6eP29tCnoEVHs3mqSeVDRESkPijcAK9dZ2/3GQ9nDDEapyZUPkRERELdgSKYOxrKiqHdhdBvsulENaLyISIiEsr8fljwZ9j9LbhaQ9Z/IDKgRelDjsqHiIhIKPvoQdj0NkTG2DOYxjc1najGVD5ERERC1aZ34MMce3vQFEg722yeIFH5EBERCUU/fwuv/gmwoMdYOHuU6URBo/IhIiISakqLYe4VUOKGVj3hd/eZThRUKh8iIiKhxLLg9eth55cQ3wKGvwBRTtOpgkrlQ0REJJQsmwbrX4aIKBj+PCS2NJ0o6FQ+REREQsX3S+Hd2+3t/vdCm95m89QSlQ8REZFQ4N4G868CywddR0DPa00nqjUqHyIiIqaVe2HelVC8C1K6wKCp4HCYTlVrVD5ERERMe+tvsG0VxCbZE4k5G5lOVKtUPkRERExa8wKsngk4IGsGJLc1najWqXyIiIiY8uNqePNGe7vfbdA+02yeOqLyISIiYsK+XTDvCvCVQoeB0PdG04nqjMqHiIhIXfOVw8tXg2cbND0N/jAdIhrOV3LD+aQiIiKhIvcf8P3H4GwMI2ZBbKLpRHVK5UNERKQurX8VPn3c3h76FLToaDaPASofIiIidaVwA7x2nb3dZzycMcRoHFNUPkREROrCgSKYOxrKiqHdhdBvsulExgRUPk455RQcDscxj+zsbABKSkrIzs6madOmNG7cmKysLAoLC2sluIiISL3h98OC/we7vwVXa8j6D0RGmU5lTEDlY+XKlezYsaPisXjxYgAuvfRSACZMmMCiRYuYP38+S5YsYfv27QwbNiz4qUVEROqTjx+CTW9BZIw9g2l8U9OJjAqodjVv3rzS/n333cepp57KBRdcgNvtZsaMGcyePZt+/foBMHPmTDp16sSyZcs477zzgpdaRESkvtj0Lnxwr709aAqknW02Twio9jUfpaWlvPjii1xzzTU4HA5Wr15NWVkZmZmHZ2fr2LEj6enp5OXlBSWsiIhIvbL7O3j1j4AFPcbC2aNMJwoJ1T7htHDhQoqKirjqqqsAKCgowOl0kpSUVOl1KSkpFBQUHPd9vF4vXq+3Yt/j8VQ3koiISOgoLYY5o6HEDa16wu/uM50oZFR75GPGjBkMGDCAtLS0GgXIycnB5XJVPFq3bl2j9xMRETHOsuD162HnlxDfAoa/AFFO06lCRrXKxw8//MB7773HH//4x4pjqamplJaWUlRUVOm1hYWFpKamHve9Jk2ahNvtrnjk5+dXJ5KIiEjoWDYN1r8MEVEw/HlIbGk6UUipVvmYOXMmLVq0YODAgRXHunfvTnR0NLm5uRXHNm7cyNatW8nIyDjue8XExJCYmFjpISIiUm99vxTevd3e7n8vtOltNk8ICviaD7/fz8yZMxkzZgxRUYd/3OVyMXbsWCZOnEhycjKJiYmMGzeOjIwM3ekiIiINg3sbzL8KLB90HQE9rzWdKCQFXD7ee+89tm7dyjXXXHPMc1OmTCEiIoKsrCy8Xi/9+/fnqaeeCkpQERGRkFbuhXlXQvEuSOkCg6aCw2E6VUhyWJZlmQ5xJI/Hg8vlwu126xSMiIjUH4vGw+qZEJsE134IyW0NB6pbgXx/a20XERGRmlrzgl08cEDWjAZXPAKl8iEiIlIT21bDmzfZ2/1ug/aZJ369qHyIiIhUW/FPMPdK8Hmhw0Doe6PpRPWCyoeIiEh1+Mrh5avB8yM0PQ3+MA0i9LV6MvS/koiISHXk/gO2fATOxjBiFsS6TCeqN1Q+REREArX+Vfj0cXt76FPQoqPZPPWMyoeIiEggCjfAa9fZ233GwxlDjMapj1Q+RERETtaBIpg7GsqKod2F0G+y6UT1ksqHiIjIyfD7YcH/g93fgqs1ZP0HIgOeKFxQ+RARETk5Hz8Em96CyBgY8V+Ib2o6Ub2l8iEiIvJLNr0LH9xrbw+aAmlnm81Tz6l8iIiInMju7+DVPwIW9BgLZ48ynajeU/kQERE5ntJimDMaStzQ6lz43X2mE4UFlQ8REZGqWBYsugF2fgnxLWD4CxDlNJ0qLKh8iIiIVGX5dFg3HyKiYPjzkJhmOlHYUPkQERE52vdL4Z3b7O3+90Kb3mbzhBmVDxERkSO5t8H8q8DyQdcR0PNa04nCjsqHiIjIIeVemHclFO+ClC4waCo4HKZThR2VDxERETh4gel42LYKYpPsicScjUynCksqHyIiIgDv/ws+nw2OSLhkBiS3NZ0obKl8iIiIrHgWPn7Y3h78KJyWaTZPmFP5EBGRhm3D6/C/m+3ti26Dc64wm6cBUPkQEZGG64dP4ZWDU6d3vxrOv9l0ogZB5UNERBqmnV/BSyPB54UOA2Hgw7qzpY6ofIiISMPj3gYvZtlrtrTuZV9gGhFpOlWDofIhIiINy4EimHUJeLZBs9PhsjkQHWc6VYOi8iEiIg1HWQnMuRx2boCEljD6FWiUbDpVg6PyISIiDYPfBwuuhR8+gZhEGPUyJKWbTtUgqXyIiEj4syx4exJseA0inTByFqR2Np2qwVL5EBGR8PfJVFjxNOCAPzwNbc83nahBU/kQEZHw9vkceO8f9vbvcqDzMKNxpBrlY9u2bYwePZqmTZsSFxdHly5dWLVqVcXzlmVxxx130LJlS+Li4sjMzOSbb74JamgREZGTsvk9eC3b3u59PZz3F7N5BAiwfOzZs4c+ffoQHR3NW2+9xYYNG3j44Ydp0qRJxWseeOABHnvsMaZPn87y5cuJj4+nf//+lJSUBD28iIjIcW3/DOZeCf5y6DIcMu8ynUgOcliWZZ3si2+99VY++eQTPv744yqftyyLtLQ0brzxRm666SYA3G43KSkpPPfcc4wcOfIXf4fH48HlcuF2u0lMTDzZaCIiIoft/g5mXAzFu6DdRXD5PIhymk4V1gL5/g5o5OP111+nR48eXHrppbRo0YKzzz6bZ599tuL5LVu2UFBQQGbm4dUAXS4XvXr1Ii8vL8CPISIiUg37dtmzlxbvgtSuMOK/Kh4hJqDy8d133zFt2jTat2/PO++8w1/+8heuv/56nn/+eQAKCgoASElJqfRzKSkpFc8dzev14vF4Kj1ERESqxbsPZl9qj3wktbHn8ohJMJ1KjhIVyIv9fj89evTg3nvvBeDss89m/fr1TJ8+nTFjxlQrQE5ODnfdpfNwIiJSQ74ymD/GvtajUVMY/SokpPzyz0mdC2jko2XLlpxxxhmVjnXq1ImtW7cCkJqaCkBhYWGl1xQWFlY8d7RJkybhdrsrHvn5+YFEEhERsScRe/16++6W6Eb2NR7NTjOdSo4joPLRp08fNm7cWOnYpk2baNOmDQBt27YlNTWV3Nzciuc9Hg/Lly8nIyOjyveMiYkhMTGx0kNERCQg7/8LPp8Njki49Dlo1cN0IjmBgE67TJgwgd69e3PvvfcyfPhwVqxYwTPPPMMzzzwDgMPhYPz48dx99920b9+etm3bMnnyZNLS0hg6dGht5BcRkYZuxbPw8cP29uBH4fT+ZvPILwqofJx77rksWLCASZMm8c9//pO2bdsydepURo0aVfGaW265heLiYq699lqKioro27cvb7/9NrGxsUEPLyIiDdyG1+F/N9vbF90G51xhNo+clIDm+agLmudDREROyg+fwgtDweeF7lfDoCngcJhO1WDV2jwfIiIiIWHnV/DSSLt4dBgIAx9W8ahHVD5ERKR+cW+zJxErcUPrXnDJDIiINJ1KAqDyISIi9ceBIph1CXi2QbPT4bI5EB1nOpUESOVDRETqh7ISmHM57NwACS1h9CvQKNl0KqkGlQ8REQl9fh8suBZ++ARiEu1p05PSTaeSalL5EBGR0GZZ8PYk2PAaRDph5CxI7Ww6ldSAyoeIiIS2T6bCiqft7T9Mh7bnG40jNafyISIioevzOfDeP+zt/jnQOctoHAkOlQ8REQlNm9+D17Lt7d7jIOOvZvNI0Kh8iIhI6Nn+Gcy9Evzl0GU4ZP7TdCIJIpUPEREJLbu/g1mXQlkxtLsQhjwJEfq6Cif60xQRkdCxb5c9e2nxLkjtAsP/C1FO06kkyFQ+REQkNHj3wezh9shHUjqMegVitcBoOFL5EBER83xlMP8q2L4G4pJh9AJISDGdSmqJyoeIiJhlWbDoBti8GKLiYNR8aHaa6VRSi1Q+RETErPfvhrWzwBEJlz4HrXqYTiS1TOVDRETMWflv+Pghe3vQFOjwO7N5pE6ofIiIiBlfLYI3b7K3L/w7dB9jNo/UGZUPERGpez/kwctjAQu6XwUX3GI6kdQhlQ8REalbO7+Gl0aAzwsdfg+/fxgcDtOppA6pfIiISN1xb7MnEStxQ6uekDUDIqNMp5I6pvIhIiJ140ARzLoEPD9Cs9Ph8rngbGQ6lRig8iEiIrWvrATmjIKdG6BxKox+BRolm04lhqh8iIhI7fL7YcGf4YelEJMIo1+2p0+XBkvlQ0REao9lwTuTYMNCiIiGES/aC8ZJg6byISIiteeTR2H5dHv7D9Oh3QVm80hIUPkQEZHa8fkceO9Oe7v/vdDlErN5JGSofIiISPBtzoXXsu3tjOsgI9tsHgkpKh8iIhJc29fCvCvBXw5dLoXf/st0IgkxKh8iIhI8u7fYc3mU7oO2F8CQpyBCXzVSmf6NEBGR4Ni3C14cBsW77DtaRrwIUU7TqSQEBVQ+/vGPf+BwOCo9OnbsWPF8SUkJ2dnZNG3alMaNG5OVlUVhYWHQQ4uISIjx7oPZw2H3d/YcHqNegdhE06kkRAU88nHmmWeyY8eOisfSpUsrnpswYQKLFi1i/vz5LFmyhO3btzNs2LCgBhYRkRDjK4P5V8H2NRCXDKMXQEKK6VQSwgJezScqKorU1NRjjrvdbmbMmMHs2bPp168fADNnzqRTp04sW7aM8847r+ZpRUQktFgWLLoBNi+GqDgYNR+anWY6lYS4gEc+vvnmG9LS0mjXrh2jRo1i69atAKxevZqysjIyMzMrXtuxY0fS09PJy8sLXmIREQkd798Na2eBIxIufQ5a9TCdSOqBgEY+evXqxXPPPUeHDh3YsWMHd911F7/+9a9Zv349BQUFOJ1OkpKSKv1MSkoKBQUFx31Pr9eL1+ut2Pd4PIF9AhERMWPlv+Hjh+ztQVOgw+/M5pF6I6DyMWDAgIrtrl270qtXL9q0acO8efOIi4urVoCcnBzuuuuuav2siIgY8tUiePMme/vCv0P3MWbzSL1So1ttk5KSOP3009m8eTOpqamUlpZSVFRU6TWFhYVVXiNyyKRJk3C73RWP/Pz8mkQSEZHa9kMevDwWsKD7VXDBLaYTST1To/Kxb98+vv32W1q2bEn37t2Jjo4mNze34vmNGzeydetWMjIyjvseMTExJCYmVnqIiEiI2vk1vDQCfF7o8Hv4/cPgcJhOJfVMQKddbrrpJgYPHkybNm3Yvn07d955J5GRkVx22WW4XC7Gjh3LxIkTSU5OJjExkXHjxpGRkaE7XUREwsFPm+G/f4ASN7TqCVkzIDLgmyZFAisfP/74I5dddhk///wzzZs3p2/fvixbtozmzZsDMGXKFCIiIsjKysLr9dK/f3+eeuqpWgkuIiJ1aOfX8ML/wb5CaN4RLp8LzkamU0k95bAsyzId4kgejweXy4Xb7dYpGBGRUFCwDl4YAvt/hpQucOVCiG9mOpWEmEC+vzVeJiIix7dtzcFTLUXQ8iy4YgE0SjadSuo5lQ8REana1uX2CrVej32Nx+iXIdZlOpWEAZUPERE51vdLYdZwKCuGNn3h8jkQk2A6lYQJlQ8REans2/fhpcuh/AC0uwhGztbFpRJUKh8iInLYxrdh3pX2PB7tL4bh/4XoWNOpJMzUaJIxEREJIxteh7mj7eLRcRCMmKXiIbVC5UNERGDdyzD/KvCXQecse4XaKKfpVBKmVD5ERBq6tbPh1T+B5YNul8OwZyEy2nQqCWMqHyIiDdmqmbDwL2D54ZwxMORJiIg0nUrCnMqHiEhDtWw6vDHe3u75Zxj8KEToa0Fqn/4tExFpiD55FN7+m73d+3oYcL9Wp5U6o1ttRUQaEsuCjx6ED+6x98+/BS76u4qH1CmVDxGRhsKy4P1/wccP2/v9bofzbzabSRoklQ8RkYbAsuDd2yHvCXv/4nug93VmM0mDpfIhIhLu/H5462ZY+W97//cPQc8/mc0kDZrKh4hIOPP7YNEN8Nl/AYd9R0v3MaZTSQOn8iEiEq585fDaX+GLueCIgKHToNtI06lEVD5ERMKSrwxe+SNsWAgRUfaspZ2HmU4lAqh8iIiEn3IvzL8aNr4JEdEw/HnoONB0KpEKKh8iIuGk7IC9Mu3m9yAyBkbOgva/NZ1KpBKVDxGRcFFaDC+NhC0fQVQcXD4H2l1oOpXIMVQ+RETCQYkHZg+HrXngbAyj5kOb3qZTiVRJ5UNEpL47UAQvZsG2VRDjgtGvQOtzTacSOS6VDxGR+mz/bnhhCBR8AXFN4IoFkHa26VQiJ6TyISJSX+3bCS8MhZ1fQqNmcOVrkNrZdCqRX6TyISJSH3m22yMeP22Cxqkw5nVo3sF0KpGTovIhIlLfFOXD84NhzxZIbGUXj6anmk4lctJUPkRE6pPdW+D5/wP3VkhqA2MWQZM2plOJBETlQ0Skvvhpsz3isXc7JJ9qj3i4WplOJRIwlQ8Rkfpg51f2iEfxTmje0b64NCHVdCqRalH5EBEJdTu+gP8Ohf0/Q0oXuHIhxDcznUqk2iJq8sP33XcfDoeD8ePHVxwrKSkhOzubpk2b0rhxY7KysigsLKxpThGRhmnbavtUy/6foeVZ9qkWFQ+p56pdPlauXMnTTz9N165dKx2fMGECixYtYv78+SxZsoTt27czbJiWcRYRCdjWZfY8HiVF0KqnXTwaJZtOJVJj1Sof+/btY9SoUTz77LM0adKk4rjb7WbGjBk88sgj9OvXj+7duzNz5kw+/fRTli1bFrTQIiJhb8vH8N9h4PVAmz5wxasQ6zKdSiQoqlU+srOzGThwIJmZmZWOr169mrKyskrHO3bsSHp6Onl5eTVLKiLSUGzOhVmXQFkxtLsIRr0MMQmmU4kETcAXnM6ZM4c1a9awcuXKY54rKCjA6XSSlJRU6XhKSgoFBQVVvp/X68Xr9VbsezyeQCOJiISPjW/DvCvAVwrtL4bh/4XoWNOpRIIqoJGP/Px8brjhBmbNmkVsbHD+Y8jJycHlclU8WrduHZT3FRGpdza8DnNH28Wj4yAYMUvFQ8JSQOVj9erV7Ny5k3POOYeoqCiioqJYsmQJjz32GFFRUaSkpFBaWkpRUVGlnyssLCQ1ter70SdNmoTb7a545OfnV/vDiIjUW+tehvlXgb8MOmfBpc9BlNN0KpFaEdBpl9/85jesW7eu0rGrr76ajh078re//Y3WrVsTHR1Nbm4uWVlZAGzcuJGtW7eSkZFR5XvGxMQQExNTzfgiImHgs1nwWjZgQbfLYcgTEBFpOpVIrQmofCQkJNC5c+XlmuPj42natGnF8bFjxzJx4kSSk5NJTExk3LhxZGRkcN555wUvtYhIuFj1H3hjgr19zhgYNBUiajQFk0jIC/oMp1OmTCEiIoKsrCy8Xi/9+/fnqaeeCvavERGp/5ZNg7dvtbd7/hkG3A8Oh9lMInXAYVmWZTrEkTweDy6XC7fbTWJiouk4IiK1Y+lUeO9Oe7v39fDbf6p4SL0WyPe31nYREalLlgVLHoAP77X3z78FLvq7ioc0KCofIiJ1xbIg95+w9BF7v9/tcP7NZjOJGKDyISJSFywL3rkNlj1p7198N/QeZzaTiCEqHyIitc3vh//dBKtm2Pu/fwh6/slsJhGDVD5ERGqT3weLrofPXgQcMPhR6D7GdCoRo1Q+RERqi68cFv4F1s0DRwQMnQbdRppOJWKcyoeISG3wlcErY2HDa+CIhKx/Q+dhplOJhASVDxGRYCv32uu0bPwfRETb67R0GmQ6lUjIUPkQEQmmsgP2yrSb34PIGBg5C9r/1nQqkZCi8iEiEiwlHpg7CrZ8BFFxcPkcaHeh6VQiIUflQ0QkGHZ/By9dBru+BmdjuHwenNLHdCqRkKTyISJSU999CPPGQEkRNE6Fy2bDr7qbTiUSslQ+RESqy7JgxbP2yrSWD9LOgZGzIbGl6WQiIU3lQ0SkOspL4X83wpoX7P2uI+wJxKLjzOYSqQdUPkREArVvF8y7ArbmAQ747V3Q+3qtTCtyklQ+REQCseMLmHM5uPMhJhGyZsDpF5tOJVKvqHyIiJysLxfAwr9C2X5IPhUumwPNTzedSqTeUfkQEfklfj8suQ+W3G/vt7sILp0JcU3M5hKpp1Q+REROxLsPFvwZvn7D3j8vG377T4jUX58i1aX/ekREjmfPD/bEYTu/hEgnDJoCZ482nUqk3lP5EBGpyvdLYd6VsP9niG8BI16E9F6mU4mEBZUPEZGjrZwBb90C/nJoeZa9OJyrlelUImFD5UNE5BBfGbz1N1g1w97vnAX/9wQ4G5nNJRJmVD5ERACKf4b5Y+D7jwEH/GYy9J2oicNEaoHKh4hIwXqYcxkUbbVXpM36N3QYYDqVSNhS+RCRhu2rN+DVa6GsGJqcYk8c1qKT6VQiYU3lQ0QaJsuCjx6ED+6x99ueD5c+D42SzeYSaQBUPkSk4SkttqdJ37DQ3u/5Z+h/D0RGG40l0lCofIhIw1KUb1/fUbAOIqJh4EPQ/SrTqUQaFJUPEWk4fsiDuaNh/0/QqBmM+C+06W06lUiDo/IhIg3D6ufhzRvBXwapXWDkbEhKN51KpEGKCOTF06ZNo2vXriQmJpKYmEhGRgZvvfVWxfMlJSVkZ2fTtGlTGjduTFZWFoWFhUEPLSJy0nzl8L9bYNH1dvE4Ywhc846Kh4hBAZWPVq1acd9997F69WpWrVpFv379GDJkCF9++SUAEyZMYNGiRcyfP58lS5awfft2hg0bVivBRUR+0f7d8OIwWPG0vX/RbfYdLc54s7lEGjiHZVlWTd4gOTmZBx98kEsuuYTmzZsze/ZsLrnkEgC+/vprOnXqRF5eHuedd95JvZ/H48HlcuF2u0lMTKxJNBFpyHZ+Za9Iu2cLRMfDsKeh02DTqUTCViDf3wGNfBzJ5/MxZ84ciouLycjIYPXq1ZSVlZGZmVnxmo4dO5Kenk5eXl51f42ISOA2vgX//q1dPJLS4Y+LVTxEQkjAF5yuW7eOjIwMSkpKaNy4MQsWLOCMM85g7dq1OJ1OkpKSKr0+JSWFgoKC476f1+vF6/VW7Hs8nkAjiYjYLAuWToHcfwIWtOkLw1+A+Kamk4nIEQIuHx06dGDt2rW43W5efvllxowZw5IlS6odICcnh7vuuqvaPy8iAkDpfnh9HKx/2d7vMRYG3K+Jw0RCUMCnXZxOJ6eddhrdu3cnJyeHbt268eijj5KamkppaSlFRUWVXl9YWEhqaupx32/SpEm43e6KR35+fsAfQkQaOPc2mDnALh4RUTDwYRj0iIqHSIiq9jUfh/j9frxeL927dyc6Oprc3NyK5zZu3MjWrVvJyMg47s/HxMRU3Lp76CEictLyV8AzF8KOtRCXDFcshHP/aDiUiJxIQKddJk2axIABA0hPT2fv3r3Mnj2bDz/8kHfeeQeXy8XYsWOZOHEiycnJJCYmMm7cODIyMk76ThcRkYB8NgveGA++UmhxJlw2216ZVkRCWkDlY+fOnVx55ZXs2LEDl8tF165deeedd/jtb38LwJQpU4iIiCArKwuv10v//v156qmnaiW4iDRgvnJYfAcse9Le7zgI/vA0xDQ2m0tETkqN5/kINs3zISIndGAPvHwNfPu+vX/B3+CCWyGixmeRRaQGAvn+1touIlJ/7NoEL42E3d9CdCMY+hSc+QfTqUQkQCofIlI/fLPYHvHwesDV2l4YrmVX06lEpBpUPkQktFkWfPq4fY0HFrQ+D0a8CI2bm04mItWk8iEioausBBbdAF/MsffPuRJ+/zBEOc3mEpEaUfkQkdDk2QFzR8G21eCIhN/dBz3/BA6H6WQiUkMqHyISen5cDXMuh30FEJsEw5+HdheaTiUiQaLyISKh5fO59hotPi807wiXvQTJ7UynEpEgUvkQkdDg90HuXfDJo/b+6QNg2DMQq/l+RMKNyoeImFfihlf+CN+8a+//+ka46HZNHCYSplQ+RMSsn7+1Jw77aRNExcKQJ6HLJaZTiUgtUvkQEXM258LLV9sjHwlp9sJwaWebTiUitUzlQ0TqnmXBsmnw7m1g+aHVuTBiFiSkmE4mInVA5UNE6la5F96YCGtftPfPGgWDpkBUjNlcIlJnVD5EpO7sLYC5V8CPK8ARARffA+f9RROHiTQwKh8iUvssC758Fd68CQ7shlgXXDITTvuN6WQiYoDKh4jUrn274M2J8NXr9n5qF7jkOWh2mtFYImKOyoeI1J4vF8CbN8L+nyEiCs6/2Z7DIzLadDIRMUjlQ0SCr/hn+N+NdvkAaHEm/GEatOxmNpeIhASVDxEJrq8WwRsToHiXvRrtr2+0RzyinKaTiUiIUPkQkeDYvxv+dzOsf9neb97JHu3QpGEichSVDxGpua/fhEXjoXinfQtt3wlwwd80d4eIVEnlQ0Sq78AeeOtW+GKOvd+sgz3a8avuZnOJSEhT+RCR6tn4Niy6AfYV2KMdva+HCydBdKzpZCIS4lQ+RCQwB4rg7Unw+Wx7v2l7GDoNWp9rNJaI1B8qHyJy8r5ZDK9fD3u3Aw7ofR1cdBtEx5lOJiL1iMqHiPyyEje8cxt89l97P/lUGPoUpJ9nNpeI1EsqHyJyYptz4fVx4NkGOOC8v0K/28HZyHQyEamnVD5EpGolHnj3dljzvL3fpK092tGmt9lcIlLvqXyIyLG++xBeuw7c+fZ+zz9D5p3gjDcaS0TCg8qHiBzm3QeL74BVM+z9pDYw5Elo+2uzuUQkrKh8iIhty0fwWjYUbbX3z/0TZP4DYhobjSUi4ScikBfn5ORw7rnnkpCQQIsWLRg6dCgbN26s9JqSkhKys7Np2rQpjRs3Jisri8LCwqCGFpEgKi2212R5frBdPFzpcOXrMPAhFQ8RqRUBlY8lS5aQnZ3NsmXLWLx4MWVlZVx88cUUFxdXvGbChAksWrSI+fPns2TJErZv386wYcOCHlxEguD7T2Bab1jxjL3f/Wr466fQ7gKzuUQkrDksy7Kq+8O7du2iRYsWLFmyhPPPPx+3203z5s2ZPXs2l1xyCQBff/01nTp1Ii8vj/PO++U5ATweDy6XC7fbTWJiYnWjiciJlO6H3H/C8umABYmtYMjjcGo/08lEpJ4K5Ps7oJGPo7ndbgCSk5MBWL16NWVlZWRmZla8pmPHjqSnp5OXl1eTXyUiwfJDHkzvA8unARaccyX8NU/FQ0TqTLUvOPX7/YwfP54+ffrQuXNnAAoKCnA6nSQlJVV6bUpKCgUFBVW+j9frxev1Vux7PJ7qRhKREyk7AO/fDXlPAhYkpMH/PQ7tM3/xR0VEgqna5SM7O5v169ezdOnSGgXIycnhrrvuqtF7iMgvyF8BC/8CP2+2988aDf3vgbgko7FEpGGq1mmX6667jjfeeIMPPviAVq1aVRxPTU2ltLSUoqKiSq8vLCwkNTW1yveaNGkSbre74pGfn1+dSCJSlbISeHcy/Ke/XTwSWsLl82HokyoeImJMQCMflmUxbtw4FixYwIcffkjbtm0rPd+9e3eio6PJzc0lKysLgI0bN7J161YyMjKqfM+YmBhiYmKqGV9EjuvHVfZox0+b7P1ul8HvciCuidlcItLgBVQ+srOzmT17Nq+99hoJCQkV13G4XC7i4uJwuVyMHTuWiRMnkpycTGJiIuPGjSMjI+Ok7nQRkSAo98KHOfDJo2D5oXEKDH4UOgwwnUxEBAjwVluHw1Hl8ZkzZ3LVVVcB9iRjN954Iy+99BJer5f+/fvz1FNPHfe0y9F0q61IDWxbAwv/Cru+sve7DIcB90OjZLO5RCTsBfL9XaN5PmqDyodINZR7YckDsHQKWD6Ibw6DpkKnQaaTiUgDEcj3t9Z2Eanvtq+1r+3YucHe75wFAx6E+KZGY4mIHI/Kh0h9VV4KHz8EHz1kj3Y0agaDHoEzhphOJiJyQiofIvVRwTpY8BcoXGfvnzEUBj4M8c2MxhIRORkqHyL1ia8MPn4EPnoA/OUQl2yXjs5avFFE6g+VD5H6ovBLWPD/oOALe7/jIBg0BRq3MJtLRCRAKh8ioc5XDp9MgQ/vB3+ZPUnY7x+yLyw9zu3vIiKhTOVDJJTt/Mq+k2X7Z/Z+h9/bt9AmpBiNJSJSEyofIqHIVw6fPmbPVOorhViXffts1+Ea7RCRek/lQyTU7Npoj3ZsW23vn/47e7QjsaXRWCIiwaLyIRIqyg7Asmnw4X3g80KMCwbcZy8Ip9EOEQkjKh8ipvnKYM0L8NGDsHeHfey038L/PQaJaWaziYjUApUPEVP8Plg3376uY8/39jFXa7joNug2UqMdIhK2VD5E6pplwVeL4IN7YNfX9rH4FnD+TdD9KoiKMRpPRKS2qXyI1BXLgm9z4f27D986G+uCPuOh15/BGW80nohIXVH5EKkLP+TB+/+CHz6x96PjIeOvkHEdxCUZjSYiUtdUPkRq0/a19kjH5sX2fmQMnPtH6DsBGjc3Gk1ExBSVD5HasGujfU3HhtfsfUcknHMFnH8LuH5lNpuIiGEqHyLBtOd7ew2WL+aA5Qcc0OVSuPBWaHqq6XQiIiFB5UMkGPYW2PN0rH7eXvwN7FVnL7oNUs4wm01EJMSofIjUxP7dsHQKrHgWyg/Yx9pdBP0mQ6vuZrOJiIQolQ+R6ijx2FOh5z0BXo99rHUvu3S0/bXZbCIiIU7lQyQQZQdg5b/h40fgwG77WGoXu3S0v1izkoqInASVD5GTUV4Kn70AHz10eP2Vpu3hor/DGUMhIsJoPBGR+kTlQ+REDq2/8sG9UPSDfcyVDhf+DbqOhEj9JyQiEij9zSlSleOuv3IzdB+j9VdERGpA5UPkSIfWX8n9F+xYax+LTYK+46HntVp/RUQkCFQ+RA754VO7dGz91N53Nobz/goZ2Vp/RUQkiFQ+RKpaf6Xnn+z1V+KbGY0mIhKOVD6k4Tp6/ZWIKDj7Cvu6Dq2/IiJSa1Q+pOGpav2VrsPt9VeS25lOJyIS9lQ+pOHw7ICPH9L6KyIihgU8M9JHH33E4MGDSUtLw+FwsHDhwkrPW5bFHXfcQcuWLYmLiyMzM5NvvvkmWHlFArd/N7w7GR47y56d1F8Gp/aDP70PI2epeIiI1LGAy0dxcTHdunXjySefrPL5Bx54gMcee4zp06ezfPly4uPj6d+/PyUlJTUOKxKQEg98eB9M7QqfPgblJdD6PLjqTbhiAfxKC7+JiJgQ8GmXAQMGMGDAgCqfsyyLqVOncvvttzNkyBAAXnjhBVJSUli4cCEjR46sWVqRk1F2wF5ldumUI9Zf6Xpw/ZXfav0VERHDgnrNx5YtWygoKCAzM7PimMvlolevXuTl5al8SO06tP7KkgdhX4F9rGl76HcbdBqi9VdEREJEUMtHQYH9F35KSkql4ykpKRXPHc3r9eL1eiv2PR5PMCNJQ+D3wRfz4MOco9ZfuRW6jtD6KyIiIcb438o5OTncddddpmNIfWRZ8NXr8P498NNG+1jjFHuejnOu1PorIiIhKqjj0KmpqQAUFhZWOl5YWFjx3NEmTZqE2+2ueOTn5wczkoQjy4Jv3oNnLoR5V9rFIzYJMu+C69fas5OqeIiIhKygjny0bduW1NRUcnNzOeusswD7NMry5cv5y1/+UuXPxMTEEBOjLwo5CZYFW/OOXX8lI9t+xLrM5hMRCWF+v4X7QBl79pfi81u0T0kwliXg8rFv3z42b95csb9lyxbWrl1LcnIy6enpjB8/nrvvvpv27dvTtm1bJk+eTFpaGkOHDg1mbmlI9u20r+lYOxt2fmkf0/orItKAlZT5KNpvF4k9+0srtov2l7GnuJQ9+8so2l/K7iOecx8ow7Lsn++YmsDb4883lj/g8rFq1Souuuiiiv2JEycCMGbMGJ577jluueUWiouLufbaaykqKqJv3768/fbbxMbGBi+1hL9yL2x8yy4cm98Dy2cfj3TCWaO0/oqIhAXLsvCUlFO03y4MdoEoZU9xWaVje446dqDMV+3f2TgmijhnZBA/ReAclnWoB4UGj8eDy+XC7XaTmJhoOo7UJcuCbWvg89mw7mUoKTr83K96wFmXQ+dhENfEWEQRkeMp8/mrHH04/M8jRiSK7dcVHSjD56/e13BkhIOkuGiSGkXTpJGTpEZOmjSKpkm8k6RG0SRXcSwpzokzqnamHQjk+9v43S4ieLbDF3PtUY6fNh0+npAG3UZCt8ug+enm8olIg2JZFsWlPvYUlx7/1MahUYniw8/t85ZX+3fGRUfSpFG0XRbiow+XhkZO+1FxzFnxuoSYKCIi6uekiSofYkbZAfj6TVg7C7778ODqskBUHHQaZI9ytL0AIswODYpI/ebzW0eNPhxxauPQseIjTm3sL8O9v4xSn79av8/hAFfcoZGIyv88NAJR+Zi9HRvdsP6uU/mQumNZkL/cLhxfLgTvERPKpWfYheOMoRCr020icqwDpb5jRiH27C+jqLjyqY3dFaWiFE9J9UcjnFERFaMPx5zaaOQ8WCQqj1IkxkUTWU9HI+qSyofUvqKt8Pkc+Pwl2P3d4eOudDjrMvvUSnI7c/lEpE75/RaekrJjLrA8+tTG7uLKRcNbXr3RCICE2KhKpywO/9M+pXHkKMShUhEXHYlDa0HVCpUPqR3effDVInuU4/uPDx+PjoczhtijHG36aL0VkXrOW37ELZ/FVZ/a2HNUiXAfKKOa11gSFeGoNNJQMSJxsEAkH1Ugkho5SYqLJipSf9eEEpUPCR6/H374xL5wdMNrUFZ8+LlTfm3fIttpMMQ0NpdRRKpkWRZ7veUUFR97gWWl6yWOKhL7S6t/y2e8M7LiAssjT2kkNXKSXHGHRuWi0TgmSqMRYUDlQ2pu93eHT6sUbT18vElbe4Sj6who0sZcPpEGpsznt2/jrGoUYn8pRcVlByefOlwsivaXUV7N4YgIB/YIwxEXVlYqEvFHneZoFI2rUTQxUQ3rIks5TOVDqqfEAxsW2qMcW/MOH49JhDP/YJeO1r3sS79FpFosy2L/wYssjxmFOOoOjUMXWxYVl7G3Brd8xkZHHHNhZdJRF1gefbdGQmz9veVTzFD5kJPn98GWJXbh+OoNKD9w8AkHnHqRfVql40CIjjMaUyQU+Y5YV6OqCyyrOqVRVMNbPhNjo4+5G8MeiTh2zohDpz4a2i2fYobKh/yyXZvsWUc/nwt7tx8+3uz0w6dVEtPM5ROpYyVlvpO6wPLIayU8JYfX1QiUMzLi2Dkjjr5D46iJqFy65VNCmMqHVO3AHlj/qj3KsW3V4eOxSdA5yx7l+NU5Oq0i9Zrfb7G3pPwEF1geOR324WMlZTW45TMmquLOjOPPYlm5aDRy6pZPCS8qH3KYrxy+fd++PXbjW+Dz2scdkXBapj3K0WEARMWYzSlShdJyP0UHjjydceSIxNFrbdR8XQ37ls+j54yoavKpI275bBRNtG75FFH5EKBwg31a5Yt5sK/w8PEWZ9qTgHUZDgkp5vJJg3K8dTWOXqjr6GsjarKuRiNn5DHTYSdXcZtnxWmO+GgSdMunSLWpfDRUxT/Duvl26djx+eHjjZpCl0vtUY7UrjqtIjVS7vMfvMjy2GsjjjyNcfTqn2W+6t/yefS6GscbhTg8t4Ru+RSpayofDUl5KWxebF/Hsekd8JfZxyOi4PTf2avHtr8Yopxmc0pIOtG6GrurvBW0ZutqxERFBHSBZZNG0STGRuuWT5F6QOUj3FkWFHxhF45182H/z4efa9kNul0OXS6B+GbmMkqdOtG6GlXNIxGMdTUSY6MqzVaZfORslseZOyLOqdEIkXCl8hGu9u20r+FYOxt2fnn4eHwL6DrcPq2Scqa5fBIUVa2rsfsEF1jWdF2N6EhHlRdYHnfuiEbRuLSuhogcReUjnJQWwzcHT6tsfg+sg2suRDqhw+/t22NP7QeR+mMPNcdbV2N3cRV3bQRpXY3GMVHHzh1xZKmId1Y+zRHvJF63fIpIEOhbqL6yLNjzPfy4EvJXwI8roGD94cIB8Kse9t0qZw6DRsnGojY0Va2rcfQoxNEXWNZkXY3ICAdJcdFHFInD5eHYUnHwOok4J84ojUaIiBkqH/VF2QHY/tnBonGwcBTvPPZ1rtb2NRzdLofmp9d9zjBS1boau4uPHX2orXU1ko+ZcErraohIeFD5CEWWBe78ykWj4AvwH/WlFhENLbtCq57Q+uDD1cpM5hBX1boaR6/qefQFlsFaV+PQ6YsqRyG0roaINEAqH6GgrMSea+PHFYcLx94dx76ucQq0Ovdg0ehl363SABdxO3pdjd1H3PJ5vFMbwVhXIzneeeypDa2rISISMJUPE9zbDhaNlfY/d3wOvtLKr3FEQmqXw0Wj1bmQlB5Wk35Vta7G7ipW9Tz61EZN19WoPOnUUddCaF0NEZFap/JR28pL7VMmhy4KzV8Jnh+PfV2jZodPnbTqCWlng7NR3eetptJyf8Uow7F3aFQ9LXbR/tJq3/Jpr6txbFFIij/+qQ2tqyEiEhpUPoJtb0HlorFjLZSXVH6NI8KeY6PVwVGN1udCk7YhMaphWRb7vOVVjkIcfYfGkac+imtwy+ehdTWaHLXSp9bVEBEJTyofNeErg4J1lW93Ldp67OvimhwsGufaZSPtHIhpXOvxyn1+ig4cXg78mJU+i6s+tVHdWz4jHFSMMBw9Z4TW1RARkUNUPgKxb1fli0K3rYHyA0e9yAEtzrCLxqGRjaan1mhUw7IsDpT57NJQfLwpsI89tbG3ButqHHnL5zGnNrSuhoiI1IDKx/H4yu1pyY+83XXPlmNfF+uyLwY9NLLxqx4Qm3j8t/VbeA4cuUz4CeaMOOJYaQ3W1bBX+ax6zgitqyEiInVN5eOQ/buPuFZjhT2qUVZ87Ouad6y43dXbsgd74k5hz4Fye0SiuIw9a/dQtL/wuNNhuw/U/JbPqkcftK6GiIjUDw2zfPh9sOtryF8O+SuxflyB4+fNx7ysNLIx2xufyXexZ7AhqiOfW6ex7UAMRRtK2bOqjANlW4AqRkNOQkJMVMWdGSc8tXFwOzlet3yKiEh4aDDlY9ePm9n4vydp4f6C1vs3EGftr3ju0Nf5t/6WrPG3Z43VntX+09ls/Qp/8ZGjBt6Dj8MiIxxVXFh5nLs2Dk5SpXU1RESkIau18vHkk0/y4IMPUlBQQLdu3Xj88cfp2bNnbf26X1Sybw99t/+nYn+fFcvn/lNZY7Vnjb89n/lPo9SZRJPGdkFo0cjJ6UfftVHFkuGJsbrlU0REJBC1Uj7mzp3LxIkTmT59Or169WLq1Kn079+fjRs30qJFi9r4lb/Ild6Fz5oNxt3kTPa3OAdHizNwNY4js5GTSw+e2tC6GiIiIrXPYVnVvfzx+Hr16sW5557LE088AYDf76d169aMGzeOW2+99YQ/6/F4cLlcuN1uEhOPf9eIiIiIhI5Avr+DfuFBaWkpq1evJjMz8/AviYggMzOTvLy8YP86ERERqWeCftrlp59+wufzkZKSUul4SkoKX3/99TGv93q9eL2HL+L0eDzBjiQiIiIhxPgtFzk5ObhcropH69atTUcSERGRWhT08tGsWTMiIyMpLCysdLywsJDU1NRjXj9p0iTcbnfFIz8/P9iRREREJIQEvXw4nU66d+9Obm5uxTG/309ubi4ZGRnHvD4mJobExMRKDxEREQlftXKr7cSJExkzZgw9evSgZ8+eTJ06leLiYq6++ura+HUiIiJSj9RK+RgxYgS7du3ijjvuoKCggLPOOou33377mItQRUREpOGplXk+akLzfIiIiNQ/Ruf5EBERETkRlQ8RERGpUyofIiIiUqdUPkRERKROqXyIiIhInaqVW21r4tDNN1rjRUREpP449L19MjfRhlz52Lt3L4DWeBEREamH9u7di8vlOuFrQm6eD7/fz/bt20lISMDhcAT1vT0eD61btyY/Pz8s5xAJ988H4f8Z9fnqv3D/jPp89V9tfUbLsti7dy9paWlERJz4qo6QG/mIiIigVatWtfo7wn0NmXD/fBD+n1Gfr/4L98+oz1f/1cZn/KURj0N0wamIiIjUKZUPERERqVMNqnzExMRw5513EhMTYzpKrQj3zwfh/xn1+eq/cP+M+nz1Xyh8xpC74FRERETCW4Ma+RARERHzVD5ERESkTql8iIiISJ1S+RAREZE61WDKx5NPPskpp5xCbGwsvXr1YsWKFaYjBc1HH33E4MGDSUtLw+FwsHDhQtORgionJ4dzzz2XhIQEWrRowdChQ9m4caPpWEE1bdo0unbtWjHpT0ZGBm+99ZbpWLXmvvvuw+FwMH78eNNRguIf//gHDoej0qNjx46mYwXdtm3bGD16NE2bNiUuLo4uXbqwatUq07GC4pRTTjnmz9DhcJCdnW06WlD4fD4mT55M27ZtiYuL49RTT+Vf//rXSa3DUhsaRPmYO3cuEydO5M4772TNmjV069aN/v37s3PnTtPRgqK4uJhu3brx5JNPmo5SK5YsWUJ2djbLli1j8eLFlJWVcfHFF1NcXGw6WtC0atWK++67j9WrV7Nq1Sr69evHkCFD+PLLL01HC7qVK1fy9NNP07VrV9NRgurMM89kx44dFY+lS5eajhRUe/bsoU+fPkRHR/PWW2+xYcMGHn74YZo0aWI6WlCsXLmy0p/f4sWLAbj00ksNJwuO+++/n2nTpvHEE0/w1Vdfcf/99/PAAw/w+OOPmwlkNQA9e/a0srOzK/Z9Pp+VlpZm5eTkGExVOwBrwYIFpmPUqp07d1qAtWTJEtNRalWTJk2sf//736ZjBNXevXut9u3bW4sXL7YuuOAC64YbbjAdKSjuvPNOq1u3bqZj1Kq//e1vVt++fU3HqDM33HCDdeqpp1p+v990lKAYOHCgdc0111Q6NmzYMGvUqFFG8oT9yEdpaSmrV68mMzOz4lhERASZmZnk5eUZTCbV5Xa7AUhOTjacpHb4fD7mzJlDcXExGRkZpuMEVXZ2NgMHDqz032O4+Oabb0hLS6Ndu3aMGjWKrVu3mo4UVK+//jo9evTg0ksvpUWLFpx99tk8++yzpmPVitLSUl588UWuueaaoC9wakrv3r3Jzc1l06ZNAHz++ecsXbqUAQMGGMkTcgvLBdtPP/2Ez+cjJSWl0vGUlBS+/vprQ6mkuvx+P+PHj6dPnz507tzZdJygWrduHRkZGZSUlNC4cWMWLFjAGWecYTpW0MyZM4c1a9awcuVK01GCrlevXjz33HN06NCBHTt2cNddd/HrX/+a9evXk5CQYDpeUHz33XdMmzaNiRMn8ve//52VK1dy/fXX43Q6GTNmjOl4QbVw4UKKioq46qqrTEcJmltvvRWPx0PHjh2JjIzE5/Nxzz33MGrUKCN5wr58SHjJzs5m/fr1YXc+HaBDhw6sXbsWt9vNyy+/zJgxY1iyZElYFJD8/HxuuOEGFi9eTGxsrOk4QXfk/3vs2rUrvXr1ok2bNsybN4+xY8caTBY8fr+fHj16cO+99wJw9tlns379eqZPnx525WPGjBkMGDCAtLQ001GCZt68ecyaNYvZs2dz5plnsnbtWsaPH09aWpqRP7+wLx/NmjUjMjKSwsLCSscLCwtJTU01lEqq47rrruONN97go48+olWrVqbjBJ3T6eS0004DoHv37qxcuZJHH32Up59+2nCymlu9ejU7d+7knHPOqTjm8/n46KOPeOKJJ/B6vURGRhpMGFxJSUmcfvrpbN682XSUoGnZsuUxRbhTp0688sorhhLVjh9++IH33nuPV1991XSUoLr55pu59dZbGTlyJABdunThhx9+ICcnx0j5CPtrPpxOJ927dyc3N7fimN/vJzc3N+zOp4cry7K47rrrWLBgAe+//z5t27Y1HalO+P1+vF6v6RhB8Zvf/IZ169axdu3aikePHj0YNWoUa9euDaviAbBv3z6+/fZbWrZsaTpK0PTp0+eYW9w3bdpEmzZtDCWqHTNnzqRFixYMHDjQdJSg2r9/PxERlb/yIyMj8fv9RvKE/cgHwMSJExkzZgw9evSgZ8+eTJ06leLiYq6++mrT0YJi3759lf4f1pYtW1i7di3Jycmkp6cbTBYc2dnZzJ49m9dee42EhAQKCgoAcLlcxMXFGU4XHJMmTWLAgAGkp6ezd+9eZs+ezYcffsg777xjOlpQJCQkHHONTnx8PE2bNg2La3duuukmBg8eTJs2bdi+fTt33nknkZGRXHbZZaajBc2ECRPo3bs39957L8OHD2fFihU888wzPPPMM6ajBY3f72fmzJmMGTOGqKjw+nocPHgw99xzD+np6Zx55pl89tlnPPLII1xzzTVmAhm5x8aAxx9/3EpPT7ecTqfVs2dPa9myZaYjBc0HH3xgAcc8xowZYzpaUFT12QBr5syZpqMFzTXXXGO1adPGcjqdVvPmza3f/OY31rvvvms6Vq0Kp1ttR4wYYbVs2dJyOp3Wr371K2vEiBHW5s2bTccKukWLFlmdO3e2YmJirI4dO1rPPPOM6UhB9c4771iAtXHjRtNRgs7j8Vg33HCDlZ6ebsXGxlrt2rWzbrvtNsvr9RrJ47AsQ9ObiYiISIMU9td8iIiISGhR+RAREZE6pfIhIiIidUrlQ0REROqUyoeIiIjUKZUPERERqVMqHyIiIlKnVD5ERESkTql8iIiISJ1S+RAREZE6pfIhIiIidUrlQ0REROrU/weNhpXpCIE3xwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = arange(1, 10);\n",
    "plot(a);\n",
    "plot(a**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ecae3-6421-4252-a836-39eda99b9f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
